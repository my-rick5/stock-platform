version: '3.8'

networks:
  macro_network:
    driver: bridge

services:
  # 1. KAFKA (KRaft Mode)
  kafka:
    image: confluentinc/cp-kafka:7.5.0
    container_name: kafka
    networks:
      - macro_network
    ports:
      - "9092:9092"
    environment:
      KAFKA_NODE_ID: 1
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_PROCESS_ROLES: 'broker,controller'
      KAFKA_CONTROLLER_QUORUM_VOTERS: '1@kafka:29093'
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:29092,CONTROLLER://0.0.0.0:29093,PLAINTEXT_HOST://0.0.0.0:9092
      CLUSTER_ID: 'MkU3OEVBNTcwNTJENDM2Qk'

  # 2. QUESTDB
  questdb:
    image: questdb/questdb:latest
    container_name: questdb
    networks:
      - macro_network
    ports:
      - "9000:9000"
      - "8812:8812"
    volumes:
      - ./questdb_data:/var/lib/questdb

  # 3. POSTGRES (MLflow Metadata)
  db:
    image: postgres:14
    container_name: mlflow_db
    networks:
      - macro_network
    environment:
      - POSTGRES_USER=mlflow
      - POSTGRES_PASSWORD=password
      - POSTGRES_DB=mlflow
    volumes:
      - ./postgres_data:/var/lib/postgresql/data

  # 4. MINIO
  minio:
    image: minio/minio:latest
    container_name: minio
    networks:
      - macro_network
    ports:
      - "9002:9000"
      - "9001:9001"
    environment:
      MINIO_ROOT_USER: admin
      MINIO_ROOT_PASSWORD: password
    command: server /data --console-address ":9001"

  # 5. MLFLOW
  mlflow:
    image: ghcr.io/mlflow/mlflow:latest
    container_name: mlflow
    networks:
      - macro_network
    ports:
      - "5000:5000"
    depends_on:
      - db
      - minio
    environment:
      - AWS_ACCESS_KEY_ID=admin
      - AWS_SECRET_ACCESS_KEY=password
      - MLFLOW_S3_ENDPOINT_URL=http://minio:9000
    command: >
      mlflow server 
      --backend-store-uri postgresql://mlflow:password@db:5432/mlflow 
      --artifacts-destination s3://mlflow-artifacts 
      --serve-artifacts 
      --host 0.0.0.0

  # 6. AIRFLOW DATABASE
  airflow-db:
    image: postgres:14
    container_name: airflow_db
    networks:
      - macro_network
    environment:
      - POSTGRES_USER=airflow
      - POSTGRES_PASSWORD=airflow
      - POSTGRES_DB=airflow
    volumes:
      - ./airflow_db_data:/var/lib/postgresql/data

  # 7. AIRFLOW WEBSERVER
  airflow-webserver:
    build: .  # Uses the Dockerfile to include dbt
    container_name: airflow_webserver
    networks:
      - macro_network
    depends_on:
      - airflow-db
    ports:
      - "8080:8080"
    environment:
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@airflow-db/airflow
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
      - _PIP_ADDITIONAL_DEPENDENCIES=apache-airflow-providers-amazon apache-airflow-providers-postgres
    volumes:
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs
      - ./tests:/opt/airflow/tests
      - ./analytics:/opt/airflow/analytics
    command: webserver

  # 8. AIRFLOW SCHEDULER
  airflow-scheduler:
    build: .  # Uses the Dockerfile to include dbt
    container_name: airflow_scheduler
    networks:
      - macro_network
    depends_on:
      - airflow-db
    environment:
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@airflow-db/airflow
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - _PIP_ADDITIONAL_DEPENDENCIES=apache-airflow-providers-amazon apache-airflow-providers-postgres
    volumes:
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs
      - ./analytics:/opt/airflow/analytics
    command: scheduler
  dbt:
    build:
      context: ./analytics
      dockerfile: Dockerfile.dbt
    volumes:
      - /Users/zacharymyrick/stock-platform/analytics:/usr/app
    working_dir: /usr/app
    profiles: ["tools"]
    depends_on:
      - questdb
    networks:
      - default
    environment:
      - DBT_PROFILES_DIR=/usr/app
      - DBT_PARTIAL_PARSE=false 
  prometheus:
    image: prom/prometheus
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
    ports:
      - "9090:9090"

  grafana:
    image: grafana/grafana
    ports:
      - "3001:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
    depends_on:
      - prometheus

  cadvisor:
    image: gcr.io/cadvisor/cadvisor:latest
    ports:
      - "8082:8080"
    volumes:
      - /:/rootfs:ro
      - /var/run:/var/run:ro
      - /sys:/sys:ro
      - /var/lib/docker/:/var/lib/docker:ro
  dashboard:
    build: 
      context: ./dashboard
    ports:
      - "8501:8501"
    networks:
      - macro_network      
    depends_on:
      - questdb

  jenkins:
      image: jenkins/jenkins:lts
      container_name: jenkins
      user: root # Required to access the docker.sock
      ports:
        - "8081:8080"
        - "50000:50000"
      volumes:
        - jenkins_home:/var/jenkins_home
        - /var/run/docker.sock:/var/run/docker.sock # Lets Jenkins run Docker commands
        - /usr/bin/docker:/usr/bin/docker           # Maps the Docker binary
      networks:
        - macro_network

volumes:
  jenkins_home: # Add this to your top-level volumes list